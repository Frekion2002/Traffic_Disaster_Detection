# 도로 재난 실시간 탐지 프로젝트

## 목차
- [소개](#소개)
- [데이터셋 소개 및 분석](#데이터셋-소개-및-분석)
- [데이터 전처리 과정](#데이터-전처리-과정)
- [시뮬레이션용 영상 데이터](#시뮬레이션용-영상-데이터)
- [주요 기능](#주요-기능)
- [모델 설계 및 기술 스택](#모델-설계-및-기술-스택)
- [하이퍼파라미터 최적화](#하이퍼파라미터-최적화)
- [임계값 조정 전략](#임계값-조정-전략)
- [성능 평가](#성능-평가)
- [실제 CCTV 영상 테스트 방법](#실제-cctv-영상-테스트-방법)
- [결론 및 향후 과제](#결론-및-향후-과제)

---

## 소개

현대 사회에서 도로 안전은 국가 사회의 중요한 과제입니다. 매년 수많은 교통사고로 인해 귀중한 생명과 재산이 위협받고 있으며, 이를 예방하고 신속하게 대응하는 것은 매우 중요한 사회적 책임입니다.   
   
본 프로젝트는 도로교통정보수집카메라와 첨단 컴퓨터 비전 기술을 결합하여 실시간으로 도로 상의 재난을 탐지하는 혁신적인 접근법을 제시합니다. YOLOv8과 같은 딥러닝 기반 객체 감지 모델을 활용함으로써, 영상 데이터를 실시간으로 분석하여 사고 위험을 조기에 감지하고 대응할 수 있는 가능성을 모색합니다. 특히 YOLOv8모델은 객체 탐지 분야에서 탁월한 성능을 보이며, 고속 처리와 높은 정확도를 동시에 달성할 수 있는 딥러닝 기반 기술입니다.   
   
 이 모델은 도로 상의 다양한 객체를 초당 수십 프레임으로 식별하고, 교통사고나 위험 상황을 실시간으로 감지할 수 있습니다.    
   
 본 프로젝트의 주요기대 효과로는 첫째, 사고 발생 시 대응 시간을 획기적으로 단축하여 인명 피해를 최소화하는 것입니다. 실시간 모니터링을 통해 위험을 빠르게 감지하고, 신속한 대응 체계를 구축할 수 있습니다. 둘째, 이 기술의 확장성입니다. 현재 개발된 모델은 교통사고, 화제, 홍수, 씽크홀의 재난 상황을 탐지하지만, 포터홀이나 도로 위 장애물 발생 여부 또한 탐지하도록 확장한다면, 교통 사고의 예방 효과까지 기대할 수 있습니다.    
    
 궁극적으로 본 프로젝트는 첨단 AI 기술을 활용한 실시간 모니터링과 즉각적인 대응을 통해 인명 피해를 최소화하고, 더 안전한 도로 환경 구축에 기여하고자 합니다.           

---

## 데이터셋 소개 및 분석

 본 프로젝트에서 사용된 데이터셋은 실시간 도로 환경의 복잡성을 포괄적으로 포착하는 핵심 자원입니다. 데이터셋은 Roboflow 사이트의 객체 탐지 / 세그멘테이션용 사진, 라벨 데이터들을 활용하여 구축하였습니다. (데이터셋의 상세 출처는 깃허브 data repository에 기술해놓았습니다.) 또한 초기 학습 이후 하드 샘플들을 증강하여 데이터셋에 추가하였습니다.    
    
 이 데이터셋은 데이터 구조를 기술하는 yaml 파일, 다양한 지역, 시간대, 기상 조건에서 수집된 1만여장의 이미지 및 일부 증강/가상 이미지 파일, 그리고 라벨 정보가 들어있는 txt 파일로 구성되어 있습니다.    
    
 학습에 사용된 이미지는 총 1만여장의 이미지로 구성되어 있으며, 개인 촬영, 실제 CCTV 사진, 뉴스 보도 자료, 게임에서 추출한 가상 이미지 등 다양한 출처를 지닙니다. 이미지의 해상도 또한 저해상도부터 고해상도 이미지까지 다양한 편입니다.     
    
 라벨 정보는 홍수(침수), 화재, 교통사고, 싱크홀의 네 가지 재난 및 사고 유형을 분류하고 있습니다. 각 라벨은 객체 클래스와 바운딩 박스 좌표 정보를 포함하여 모델이 정확한 위치와 유형을 학습할 수 있도록 설계되었습니다. 이러한 정교한 라벨링은 YOLOv8 모델의 객체 탐지 정확도를 크게 향상시키는 핵심 요소입니다.    
    
 이러한 데이터의 풍부한 다양성은 YOLOv8 기반 재난 탐지 모델의 학습과 성능 향상에 결정적인 역할을 합니다. 다양한 시나리오와 환경에서 수집된 데이터는 모델의 일반화 능력과 정확성을 크게 향상시킬 수 있습니다.   

---

## 데이터 전처리 과정

 본 프로젝트에서 사용된 데이터셋은 실시간 도로 환경의 복잡성을 포괄적으로 포착하는 핵심 자원입니다. 데이터셋은 Roboflow 사이트의 객체 탐지 / 세그멘테이션용 사진, 라벨 데이터들을 활용하여 구축하였습니다. (데이터셋의 상세 출처는 깃허브 data repository에 기술해놓았습니다.) 또한 초기 학습 이후 하드 샘플들을 증강하여 데이터셋에 추가하였습니다.   
    
 이 데이터셋은 데이터 구조를 기술하는 yaml 파일, 다양한 지역, 시간대, 기상 조건에서 수집된 1만여장의 이미지 및 일부 증강/가상 이미지 파일, 그리고 라벨 정보가 들어있는 txt 파일로 구성되어 있습니다.   
    
 학습에 사용된 이미지는 총 1만여장의 이미지로 구성되어 있으며, 개인 촬영, 실제 CCTV 사진, 뉴스 보도 자료, 게임에서 추출한 가상 이미지 등 다양한 출처를 지닙니다. 이미지의 해상도 또한 저해상도부터 고해상도 이미지까지 다양한 편입니다.     
    
 라벨 정보는 홍수(침수), 화재, 교통사고, 싱크홀의 네 가지 재난 및 사고 유형을 분류하고 있습니다. 각 라벨은 객체 클래스와 바운딩 박스 좌표 정보를 포함하여 모델이 정확한 위치와 유형을 학습할 수 있도록 설계되었습니다. 이러한 정교한 라벨링은 YOLOv8 모델의 객체 탐지 정확도를 크게 향상시키는 핵심 요소입니다.   
   
 이러한 데이터의 풍부한 다양성은 YOLOv8 기반 재난 탐지 모델의 학습과 성능 향상에 결정적인 역할을 합니다. 다양한 시나리오와 환경에서 수집된 데이터는 모델의 일반화 능력과 정확성을 크게 향상시킬 수 있습니다.   

---

## 시뮬레이션용 영상 데이터

실제 적용 상황을 시뮬레이션하기 위해 유튜브를 통해 홍수/화재/교통사고/싱크홀 영상을 수집하였고, 재난 상황이 없는 일상 데이터 수집을 위해 직접 영상을 촬영하였습니다. 수집한 영상들에 대해서 필요한 부분만 추출하기 위해 크롭 등 처리를 진행했습니다.  


---

## 재난 탐지 모델 설계

 본 프로젝트의 재난 탐지 모델은 최신 딥러닝 객체 탐지 알고리즘인 YOLOv8을 기반으로 설계되었습니다. YOLOv8은 이전 버전대비 더 빠른 추론 속도와 높은 정확도를 동시에 제공합니다. 특히 작은 객체 탐지 성능이 크게 향상되어, 낙하물이나 파편 등 도로 위의 다양한 크기의 재난 요소를 효과적으로 감지할 수 있습니다. YOLOv8이상의 버전의 모델의 경우 자체 성능은 v8보다 우수하지만, YOLOv8에 비해 데이터 인프라가 부족한 한계 때문에 우수한 성능과 데이터 인프라 좋은 YOLOv8을 사용합니다. 
    
 모델 설계의 핵심은 다중 스케일 피라미드 네트워크 구조입니다. 이 구조는 작은 객체부터 큰 객체까지 다양한 크기의 재난 요소를 효과적으로 탐지할 수 있게 해줍니다. 특히 도로 환경에서 발생할 수 있는 교통사고, 씽크홀, 화재, 홍수의 다양한 재난 유형을 정확하게 식별하도록 모델을 구성했습니다.

---

## 모델 설계 및 기술 스택

- **모델**: YOLOv8 기반 객체 탐지 딥러닝 모델
  - 빠른 추론 속도와 높은 정확도, 작은 객체 탐지 성능 우수
  - 다중 스케일 피라미드 네트워크 구조 채택
- **프레임워크**: Python, PyTorch, Ultralytics YOLOv8
- **데이터**: 도로 CCTV 영상, 유튜브 재난 영상, 직접 촬영 데이터 등
- **하드웨어 권장 사양**:
  - GPU (최소 4GB 메모리)
  - RAM 8GB 이상

---

## 하이퍼파라미터 최적화
 하이퍼파라미터의 튜닝은 optuna 라이브러리를 활용합니다. Optuna는 Bayesian Optimization 기반의 효율적인 탐색 전략을 통해 최적의 하이퍼파라미터를 찾아냅니다
- **주요 하이퍼파라미터**:
  - Learning Rate: 1e-4 ~ 1e-1
  - Batch Size: 8, 16, 32
  - Mosaic: 0.0 ~ 1.0
  - Epochs: 50 (고정)

---

## 임계값 조정 전략
 본 프로젝트는 도로 속 재난 상황이 발생하면 이를 빠르게 탐지하여 신속히 대응하는데 목표를 두고 있습니다. 따라서 Recall이 더 중요한 지표라고 판단하였고, 이를 높이기 위해 각 class별로 임계값을 다르게 조절하여 도로 위 재난 상황을 놓치는 경우를 최소화하였습니다.

---

## 성능 평가

- **평가지표**:
  - Precision: 0.8825
  - Recall: 0.8272
  - mAP50: 0.8835
    
- **설명**:
  - Precision: 양성 예측 중 실제 양성 비율
  - Recall: 실제 양성 중 모델이 맞게 예측한 비율
  - mAP50: 임계값 0.5에서의 mean Average Precision

---

## 실제 CCTV 영상 테스트 방법

- 고속도로/시내도로 CCTV(15~30fps)에서 15프레임 단위로 탐지

---

## 결론 및 향후 과제

본 프로젝트의 도로 재난 탐지 모델은 높은 학습 결과 지표에도 불구하고 몇 가지 중요한 한계점 및 개선 가능성을 가지고 있습니다.    
첫째로, 모델이 동영상의 프레임 기반으로 시뮬레이션 한 실제 상황에 대하여 미흡한 성과를 보인다는 점입니다. 특히, 화면 상에서 자동차가 겹치는 것처럼 보이는 경우에 모델이 교통 사고로 인식하는 경우가 많습니다. 이는 모델이 시계열 데이터가 아니라 단순 이미지 데이터로 학습한 것에서 오는 한계점인 것으로 생각됩니다.     
 이를 극복하기 위해서 객체 탐지 뿐만 아니라 시계열 데이터 학습을 기반으로 한 멀티 트래킹을 적용하여 각 차량별 optical 벡터를 추출하고, 벡터 변화가 급작스럽거나 비정상적인 경우에 교통사고 판단 threshold 값을 낮추는 방법이나, homography를 사용하는 방법 등을 적용해보고자 합니다.   
    
 둘째로, 열악한 기상 환경 등 특이 케이스에 대한 재난 탐지율에 대한 문제입니다. 이를 개선하기 위해 향후 연구에서는 더욱 다양하고 극한 상황의 데이터셋을 확보해야 합니다. 특히 야간, 폭우, 짙은 안개 등 까다로운 환경에서의 데이터 수집과 학습이 필요합니다.
    
 마지막으로, 모델의 경량화를 통해 실시간 추론 속도를 개선하고, 모바일 및 엣지 디바이스에서도 효과적으로 작동할 수 있도록 최적화해야 합니다.   
    
 궁극적으로 본 모델은 도로 안전 시스템의 혁신적인 잠재력을 보여주었으며, 지속적인 기술 개선을 통해 실제 교통 인프라에 적용될 수 있는 실용적인 솔루션으로 발전할 수 있을 것입니다. 
    
위 내용을 정리하면 아래 세 가지 내용입니다.
1. 모델 학습 방법 및 전체 알고리즘 수정
2. 데이터의 지속적인 다양성 확보
3. 시스템의 실시간 대응성 보장

- 15프레임씩 탐지 결과, 동일 클래스 재난이 연속 5회 이상 감지될 때만 해당 재난 발생으로 판정
- 홍수, 씽크홀, 화재: 유튜브 CCTV 영상 활용
- 정상 도로: 직접 핸드폰 촬영 영상 활용
