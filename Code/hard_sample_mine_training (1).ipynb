{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "41a825b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "import os\n",
    "import shutil\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "import ultralytics\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import defaultdict\n",
    "from pathlib import Path\n",
    "import glob\n",
    "import optuna\n",
    "from optuna.visualization import (\n",
    "    plot_optimization_history,\n",
    "    plot_param_importances,\n",
    "    plot_parallel_coordinate,\n",
    "    plot_slice\n",
    ")\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import random\n",
    "from PIL import Image, ImageEnhance, ImageOps\n",
    "os.environ['CUBLAS_WORKSPACE_CONFIG'] = ':4096:8'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "49cd636d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch Î≤ÑÏ†Ñ: 2.0.1+cu117\n",
      "CUDA ÏÇ¨Ïö© Í∞ÄÎä•: True\n",
      "Ultralytics Î≤ÑÏ†Ñ: 8.3.0\n",
      "CUDA Î≤ÑÏ†Ñ: 11.7\n",
      "Î™®Îç∏ ÏûëÏóÖ Ïú†Ìòï: detect\n"
     ]
    }
   ],
   "source": [
    "print(f\"PyTorch Î≤ÑÏ†Ñ: {torch.__version__}\")\n",
    "print(f\"CUDA ÏÇ¨Ïö© Í∞ÄÎä•: {torch.cuda.is_available()}\")\n",
    "print(f\"Ultralytics Î≤ÑÏ†Ñ: {ultralytics.__version__}\")\n",
    "print(f\"CUDA Î≤ÑÏ†Ñ: {torch.version.cuda}\")\n",
    "\n",
    "model = YOLO('yolov8n.pt')\n",
    "print(f\"Î™®Îç∏ ÏûëÏóÖ Ïú†Ìòï: {model.task}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "da6530c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ÏûêÎèô Ï†ïÏ†ú Ïä§ÌÅ¨Î¶ΩÌä∏ (Î∞ïÏä§ Ïö∞ÏÑ† Ïú†ÏßÄ)\n",
    "\n",
    "def clean_labels(label_dir):\n",
    "    for filename in os.listdir(label_dir):\n",
    "        filepath = os.path.join(label_dir, filename)\n",
    "        with open(filepath, 'r') as f:\n",
    "            lines = [l for l in f.readlines() if len(l.split()) == 5]\n",
    "        \n",
    "        with open(filepath, 'w') as f:\n",
    "            f.writelines(lines)\n",
    "        \n",
    "clean_labels(\"C:/Users/user/Downloads/dataset/datasetHard/labels/train\")\n",
    "clean_labels(\"C:/Users/user/Downloads/dataset/datasetHard/labels/val\")\n",
    "clean_labels(\"C:/Users/user/Downloads/dataset/datasetHard/labels/test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "aaaef3d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ÏÇ≠Ï†úÎêú ÎπÑÏñ¥ÏûàÎäî ÎùºÎ≤® ÌååÏùº: 0Í∞ú\n",
      "Ìï®Íªò ÏÇ≠Ï†úÎêú Ïù¥ÎØ∏ÏßÄ ÌååÏùº: 0Í∞ú\n",
      "ÏÇ≠Ï†úÎêú ÎπÑÏñ¥ÏûàÎäî ÎùºÎ≤® ÌååÏùº: 0Í∞ú\n",
      "Ìï®Íªò ÏÇ≠Ï†úÎêú Ïù¥ÎØ∏ÏßÄ ÌååÏùº: 0Í∞ú\n",
      "ÏÇ≠Ï†úÎêú ÎπÑÏñ¥ÏûàÎäî ÎùºÎ≤® ÌååÏùº: 0Í∞ú\n",
      "Ìï®Íªò ÏÇ≠Ï†úÎêú Ïù¥ÎØ∏ÏßÄ ÌååÏùº: 0Í∞ú\n"
     ]
    }
   ],
   "source": [
    "# ÎπÑÏñ¥ÏûàÎäî ÌååÏùºÏù¥ ÏûàÎäî Í≤ΩÏö∞ ÏÑ±Îä• Ï†ÄÌïòÎ•º ÏïºÍ∏∞Ìï† Ïàò ÏûàÏúºÎØÄÎ°ú ÎπÑÏñ¥ ÏûàÎäî label ÌååÏùºÍ≥º Ïù¥ÎØ∏ÏßÄÎèÑ Í∞ôÏù¥ ÏÇ≠Ï†úÌïòÎäî ÌååÏùº\n",
    "\n",
    "def clean_empty_labels(label_dir, image_dir=None, delete_images=False):\n",
    "    label_dir = Path(label_dir)\n",
    "    if image_dir:\n",
    "        image_dir = Path(image_dir)\n",
    "\n",
    "    removed_labels = 0\n",
    "    removed_images = 0\n",
    "\n",
    "    for label_file in label_dir.glob(\"*.txt\"):\n",
    "        if label_file.stat().st_size == 0:  # ÌååÏùºÏù¥ ÎπÑÏñ¥ÏûàÎäîÏßÄ ÌôïÏù∏\n",
    "            # ÎùºÎ≤® ÌååÏùº ÏÇ≠Ï†ú\n",
    "            label_file.unlink()\n",
    "            removed_labels += 1\n",
    "\n",
    "            if delete_images and image_dir:\n",
    "                # Ïù¥ÎØ∏ÏßÄ ÌååÏùºÎ™Ö Ï∂îÏ†ï (ÌôïÏû•Ïûê jpg, png Îì±)\n",
    "                stem = label_file.stem\n",
    "                for ext in ['.jpg', '.jpeg', '.png', '.bmp']:\n",
    "                    img_file = image_dir / f\"{stem}{ext}\"\n",
    "                    if img_file.exists():\n",
    "                        img_file.unlink()\n",
    "                        removed_images += 1\n",
    "                        break\n",
    "\n",
    "    print(f\"ÏÇ≠Ï†úÎêú ÎπÑÏñ¥ÏûàÎäî ÎùºÎ≤® ÌååÏùº: {removed_labels}Í∞ú\")\n",
    "    if delete_images:\n",
    "        print(f\"Ìï®Íªò ÏÇ≠Ï†úÎêú Ïù¥ÎØ∏ÏßÄ ÌååÏùº: {removed_images}Í∞ú\")\n",
    "\n",
    "        \n",
    "# ÎùºÎ≤®Í≥º Ïù¥ÎØ∏ÏßÄ Î™®Îëê ÏÇ≠Ï†ú\n",
    "clean_empty_labels(\n",
    "    label_dir=r\"C:\\Users\\user\\Downloads\\dataset\\datasetHard\\labels\\train\",\n",
    "    image_dir=r\"C:\\Users\\user\\Downloads\\dataset\\datasetHard\\images\\train\",\n",
    "    delete_images=True\n",
    ")\n",
    "\n",
    "clean_empty_labels(\n",
    "    label_dir=r\"C:\\Users\\user\\Downloads\\dataset\\datasetHard\\labels\\val\",\n",
    "    image_dir=r\"C:\\Users\\user\\Downloads\\dataset\\datasetHard\\images\\val\",\n",
    "    delete_images=True\n",
    ")\n",
    "\n",
    "clean_empty_labels(\n",
    "    label_dir=r\"C:\\Users\\user\\Downloads\\dataset\\datasetHard\\labels\\test\",\n",
    "    image_dir=r\"C:\\Users\\user\\Downloads\\dataset\\datasetHard\\images\\test\",\n",
    "    delete_images=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7cbf1e65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[C:\\Users\\user\\Downloads\\dataset\\datasetHard\\labels\\train] ÎπÑÏñ¥ÏûàÎäî ÌååÏùºÏù¥ Ï°¥Ïû¨ÌïòÏßÄ ÏïäÏäµÎãàÎã§.\n",
      "[C:\\Users\\user\\Downloads\\dataset\\datasetHard\\labels\\val] ÎπÑÏñ¥ÏûàÎäî ÌååÏùºÏù¥ Ï°¥Ïû¨ÌïòÏßÄ ÏïäÏäµÎãàÎã§.\n",
      "[C:\\Users\\user\\Downloads\\dataset\\datasetHard\\labels\\test] ÎπÑÏñ¥ÏûàÎäî ÌååÏùºÏù¥ Ï°¥Ïû¨ÌïòÏßÄ ÏïäÏäµÎãàÎã§.\n"
     ]
    }
   ],
   "source": [
    "# ÎπÑÏñ¥ÏûàÎäî ÌååÏùºÏù¥ Ï°¥Ïû¨ÌïòÎäîÏßÄ ÌôïÏù∏ÌïòÎäî ÏΩîÎìú\n",
    "\n",
    "def check_labels(label_path):\n",
    "    empty_found = False  # ÎπÑÏñ¥ÏûàÎäî ÌååÏùºÏù¥ Î∞úÍ≤¨ÎêòÏóàÎäîÏßÄ Ïó¨Î∂Ä\n",
    "    for lbl_file in Path(label_path).glob(\"*.txt\"):\n",
    "        with open(lbl_file) as f:\n",
    "            lines = f.readlines()\n",
    "            if not lines:\n",
    "                print(f\"Empty file: {lbl_file}\")\n",
    "                empty_found = True\n",
    "            for line in lines:\n",
    "                parts = line.strip().split()\n",
    "                if len(parts) != 5:\n",
    "                    print(f\"Invalid line in {lbl_file}: {line}\")\n",
    "    if not empty_found:\n",
    "        print(f\"[{label_path}] ÎπÑÏñ¥ÏûàÎäî ÌååÏùºÏù¥ Ï°¥Ïû¨ÌïòÏßÄ ÏïäÏäµÎãàÎã§.\")\n",
    "\n",
    "check_labels(r\"C:\\Users\\user\\Downloads\\dataset\\datasetHard\\labels\\train\")\n",
    "check_labels(r\"C:\\Users\\user\\Downloads\\dataset\\datasetHard\\labels\\val\")\n",
    "check_labels(r\"C:\\Users\\user\\Downloads\\dataset\\datasetHard\\labels\\test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4e44460a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0Í∞úÏùò Ï∫êÏãú ÌååÏùº ÏÇ≠Ï†ú ÏôÑÎ£å\n"
     ]
    }
   ],
   "source": [
    "# YOLO ÌïôÏäµ Í≥ºÏ†ïÏóêÏÑú ÏÉùÏÑ±ÎêòÎäî Ï∫êÏãú ÌååÏùº ÏÇ≠Ï†úÌïòÎäî ÏΩîÎìú\n",
    "\n",
    "cache_files = glob.glob(r\"C:/Users/user/Downloads/dataset/datasetHard/labels/*.cache\")\n",
    "for f in cache_files:\n",
    "    os.remove(f)\n",
    "print(f\"{len(cache_files)}Í∞úÏùò Ï∫êÏãú ÌååÏùº ÏÇ≠Ï†ú ÏôÑÎ£å\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6067b7b8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train ÌÅ¥ÎûòÏä§Î≥Ñ Ïù∏Ïä§ÌÑ¥Ïä§ Ïàò:\n",
      "Class 0: 4256Í∞ú\n",
      "Class 1: 2596Í∞ú\n",
      "Class 2: 5858Í∞ú\n",
      "Class 3: 786Í∞ú\n",
      "val ÌÅ¥ÎûòÏä§Î≥Ñ Ïù∏Ïä§ÌÑ¥Ïä§ Ïàò:\n",
      "Class 0: 408Í∞ú\n",
      "Class 1: 137Í∞ú\n",
      "Class 2: 251Í∞ú\n",
      "Class 3: 140Í∞ú\n",
      "test ÌÅ¥ÎûòÏä§Î≥Ñ Ïù∏Ïä§ÌÑ¥Ïä§ Ïàò:\n",
      "Class 0: 192Í∞ú\n",
      "Class 1: 284Í∞ú\n",
      "Class 2: 135Í∞ú\n",
      "Class 3: 176Í∞ú\n"
     ]
    }
   ],
   "source": [
    "# ÌÅ¥ÎûòÏä§Î≥Ñ Ïù∏Ïä§ÌÑ¥Ïä§ ÏàòÎ•º ÌôïÏù∏Ìï† Ïàò ÏûàÎäî ÏΩîÎìú\n",
    "\n",
    "def count_instance_per_class(name, label_dir):\n",
    "    class_counts = defaultdict(int)\n",
    "\n",
    "    for label_file in Path(label_dir).glob(\"*.txt\"):\n",
    "        with open(label_file) as f:\n",
    "            for line in f:\n",
    "                if line.strip():\n",
    "                    class_id = int(line.split()[0])\n",
    "                    class_counts[class_id] += 1\n",
    "\n",
    "    print(\"{} ÌÅ¥ÎûòÏä§Î≥Ñ Ïù∏Ïä§ÌÑ¥Ïä§ Ïàò:\".format(name))\n",
    "    class_counts = dict(sorted(class_counts.items()))\n",
    "    for cls, cnt in class_counts.items():\n",
    "        print(f\"Class {cls}: {cnt}Í∞ú\")\n",
    "\n",
    "count_instance_per_class(\"train\", r\"C:\\Users\\user\\Downloads\\dataset\\datasetHard\\labels\\train\")\n",
    "count_instance_per_class(\"val\", r\"C:\\Users\\user\\Downloads\\dataset\\datasetHard\\labels\\val\")\n",
    "count_instance_per_class(\"test\", r\"C:\\Users\\user\\Downloads\\dataset\\datasetHard\\labels\\test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfc1d791",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ÌïòÏù¥ÌçºÌååÎ¶¨ÎØ∏ÌÑ∞ + ÌååÎùºÎØ∏ÌÑ∞ ÌäúÎãù ÌïòÎäî Î∂ÄÎ∂Ñ\n",
    "\n",
    "def objective(trial):\n",
    "    try:\n",
    "        # ÌïòÏù¥ÌçºÌååÎùºÎØ∏ÌÑ∞ ÏÑúÏ†úÏä§Ï≥î\n",
    "        lr0 = trial.suggest_float('lr0', 1e-4, 1e-1, log=True)\n",
    "        batch = trial.suggest_categorical('batch', [8, 16, 32])\n",
    "        mosaic = trial.suggest_float('mosaic', 0.0, 1.0)\n",
    "        epochs = 50  # Í≥†Ï†ïÍ∞í ÏÇ¨Ïö©\n",
    "\n",
    "        # Î™®Îç∏ Ï¥àÍ∏∞Ìôî Î∞è ÌïôÏäµ\n",
    "        model = YOLO('yolov8n.pt')\n",
    "        results = model.train(\n",
    "            data=r\"C:\\Users\\user\\Downloads\\dataset\\datasetHard\\data.yaml\",\n",
    "            epochs=epochs,\n",
    "            lr0=lr0,\n",
    "            batch=batch,\n",
    "            mosaic=mosaic,\n",
    "            imgsz=800,\n",
    "            device='cuda',\n",
    "            patience=20,\n",
    "            verbose=False,  # ÌïôÏäµ Î°úÍ∑∏ Í∞ÑÏÜåÌôî\n",
    "            amp=True,       # Î©îÎ™®Î¶¨ Ï†àÏïΩ\n",
    "            plots=False     # Optuna Ïã§ÌñâÏãú ÌîåÎ°Ø ÏÉùÏÑ± Î∞©ÏßÄ\n",
    "        )\n",
    "\n",
    "        # mAP50 Í∞í Ï∂îÏ∂ú (Ultralytics Î≤ÑÏ†ÑÎ≥Ñ Ìò∏ÌôòÏÑ± Ï≤òÎ¶¨)\n",
    "        try:\n",
    "            map50 = results.metrics['metrics/val_map_0.5']\n",
    "        except AttributeError:\n",
    "            map50 = results.metrics.map_50  # 8.3.0+ Î≤ÑÏ†Ñ\n",
    "\n",
    "        return map50\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Trial failed with error: {e}\")\n",
    "        return 0.0  # Ïã§Ìå®Ïãú 0 Î∞òÌôò\n",
    "\n",
    "# Optuna Ïä§ÌÑ∞Îîî Ïã§Ìñâ\n",
    "study = optuna.create_study(\n",
    "    direction='maximize',\n",
    "    sampler=optuna.samplers.TPESampler(seed=42)  # Ïû¨ÌòÑÏÑ± ÏúÑÌï¥ ÏãúÎìú Í≥†Ï†ï\n",
    ")\n",
    "study.optimize(objective, n_trials=10, show_progress_bar=True)\n",
    "\n",
    "# Í≤∞Í≥º Ï∂úÎ†•\n",
    "print(\"\\n=== Best parameters ===\")\n",
    "print(study.best_params)\n",
    "print(f\"Best mAP50: {study.best_value:.3f}\")\n",
    "\n",
    "# ÏãúÍ∞ÅÌôî\n",
    "plot_optimization_history(study).show()\n",
    "plot_param_importances(study).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0b688b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ÏµúÏ†ÅÌôî ÌïòÏù¥ÌçºÌååÎùºÎØ∏ÌÑ∞ÏôÄ ÌååÎü¨ÎØ∏ÌÑ∞ Í∞Ñ ÏÉÅÍ¥ÄÍ¥ÄÍ≥Ñ, ÌååÎùºÎØ∏ÌÑ∞Î≥Ñ ÏÑ±Îä• Î∂ÑÌè¨ ÏãúÍ∞ÅÌôî ÌååÌä∏\n",
    "\n",
    "# 1. ÏµúÏ†ÅÌôî ÌûàÏä§ÌÜ†Î¶¨(Í∞Å trialÎ≥Ñ best value Î≥ÄÌôî)\n",
    "fig1 = plot_optimization_history(study)\n",
    "fig1.show()\n",
    "\n",
    "# 2. ÌïòÏù¥ÌçºÌååÎùºÎØ∏ÌÑ∞ Ï§ëÏöîÎèÑ(Ïñ¥Îñ§ ÌååÎùºÎØ∏ÌÑ∞Í∞Ä ÏÑ±Îä•Ïóê ÏòÅÌñ•Ïù¥ ÌÅ∞ÏßÄ)\n",
    "fig2 = plot_param_importances(study)\n",
    "fig2.show()\n",
    "\n",
    "# 3. ÌååÎùºÎØ∏ÌÑ∞ Í∞Ñ ÏÉÅÍ¥ÄÍ¥ÄÍ≥Ñ(Parallel Coordinate)\n",
    "fig3 = plot_parallel_coordinate(study)\n",
    "fig3.show()\n",
    "\n",
    "# 4. ÌååÎùºÎØ∏ÌÑ∞Î≥Ñ ÏÑ±Îä• Î∂ÑÌè¨(Slice Plot)\n",
    "fig4 = plot_slice(study)\n",
    "fig4.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1579d60f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model path: runs/detect/train54/weights/best.pt\n",
      "\n",
      "üìä ThresholdÎ≥Ñ ÌÖåÏä§Ìä∏ Í≤∞Í≥º\n",
      "Threshold |   mAP50   | Precision |  Recall\n",
      "---------------------------------------------\n",
      "Ultralytics 8.3.0  Python-3.10.9 torch-2.0.1+cu117 CUDA:0 (NVIDIA GeForce RTX 3080, 10240MiB)\n",
      "Model summary (fused): 186 layers, 2,685,148 parameters, 0 gradients, 6.8 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\Users\\user\\Downloads\\dataset\\dataset\\labels\\test.cache... 561 images, 0 backgrounds, 0 corrupt: 100%|‚ñà\u001b[0m\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 18/18 [00:45\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        561        687      0.883      0.827      0.884      0.668\n",
      "                 flood        135        207       0.86      0.816       0.85      0.712\n",
      "                  fire        106        142      0.924      0.965      0.976      0.697\n",
      "              accident        236        249      0.902      0.775      0.885      0.626\n",
      "              sinkhole         84         89      0.844      0.753      0.824      0.635\n",
      "Speed: 0.8ms preprocess, 2.4ms inference, 0.0ms loss, 1.0ms postprocess per image\n",
      "Results saved to \u001b[1mruns\\detect\\disaster_detection_test31\u001b[0m\n",
      "  0.8835  |  0.8825  |  0.8272\n"
     ]
    }
   ],
   "source": [
    "# thresholdÎ•º Î≥ÄÍ≤ΩÌï¥Í∞ÄÎ©¥ÏÑú test\n",
    "\n",
    "def test_model_with_thresholds(model,test_params):\n",
    "    results_list = []\n",
    "    print(\"\\nüìä ThresholdÎ≥Ñ ÌÖåÏä§Ìä∏ Í≤∞Í≥º\")\n",
    "    print(\"Threshold |   mAP50   | Precision |  Recall\")\n",
    "    print(\"---------------------------------------------\")\n",
    "\n",
    "    test_params['conf'] = 0.01\n",
    "    results = model.val(**test_params)\n",
    "        # Í≤∞Í≥º Ï†ÄÏû• Î∞è Ï∂úÎ†•\n",
    "    map50 = results.box.map50\n",
    "    precision = np.mean(results.box.p)\n",
    "    recall = np.mean(results.box.r)\n",
    "    print(f\"  {map50:.4f}  |  {precision:.4f}  |  {recall:.4f}\")\n",
    "    results_list.append({\n",
    "        'threshold': 0.01,\n",
    "        'mAP50': map50,\n",
    "        'precision': precision,\n",
    "        'recall': recall\n",
    "    })\n",
    "    return results_list\n",
    "\n",
    "# 1. Î™®Îç∏ Î°úÎìú\n",
    "best_model_path = \"runs/detect/train54/weights/best.pt\"\n",
    "print(\"Best model path:\", best_model_path)\n",
    "model = YOLO(best_model_path)\n",
    "\n",
    "# 2. ÌÖåÏä§Ìä∏ ÌååÎùºÎØ∏ÌÑ∞ ÏÑ§Ï†ï\n",
    "test_params = {\n",
    "    'data': r\"C:\\Users\\user\\Downloads\\dataset\\datasetHard\\data.yaml\",\n",
    "    'split': 'test',\n",
    "    'batch': 32,\n",
    "    'name': 'disaster_detection_test',\n",
    "    'plots': True,\n",
    "    'save_json': False\n",
    "}\n",
    " \n",
    "results = test_model_with_thresholds(model, test_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfa3a421",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ÎûúÎç§ 5Í∞ú Ïù¥ÎØ∏ÏßÄÏóê ÎåÄÌïú ÌÖåÏä§Ìä∏ ÏãúÍ∞ÅÌôî\n",
    "\n",
    "def visualize_extreme_diverse_predictions(model):\n",
    "    test_images_dir = r\"C:\\Users\\user\\Downloads\\dataset\\datasetHard\\images\\test\"\n",
    "    all_images = os.listdir(test_images_dir)\n",
    "\n",
    "    # ÌååÏùºÎ™ÖÏóêÏÑú Ï≤´ Îã®Ïñ¥Î°ú Í∑∏Î£πÌôî\n",
    "    image_groups = defaultdict(list)\n",
    "    for img in all_images:\n",
    "        if img:\n",
    "            group_key = img.split('_')[0]  # Ïòà: 'cat_01.jpg' ‚Üí 'cat'\n",
    "            image_groups[group_key].append(img)\n",
    "\n",
    "    # Í∞Å Í∑∏Î£πÏóêÏÑú ÌïòÎÇòÏî© ÎΩëÏïÑ Îã§ÏñëÏÑ± ÌôïÎ≥¥\n",
    "    selected_images = [random.choice(group) for group in image_groups.values()]\n",
    "\n",
    "    # Í∑∏Î£πÏù¥ 5Í∞ú Ïù¥ÏÉÅÏù¥Î©¥ ÎûúÎç§ÌïòÍ≤å 5Í∞úÎßå ÏÑ†ÌÉù\n",
    "    if len(selected_images) > 5:\n",
    "        selected_images = random.sample(selected_images, 5)\n",
    "\n",
    "    # ÏÑ†ÌÉùÎêú Ïù¥ÎØ∏ÏßÄÏóê ÎåÄÌï¥ ÏòàÏ∏° Î∞è Í≤∞Í≥º Ï†ÄÏû•\n",
    "    for img_name in selected_images:\n",
    "        img_path = os.path.join(test_images_dir, img_name)\n",
    "        results = model.predict(\n",
    "            source=img_path,\n",
    "            save=True,\n",
    "            conf=0.01,  # Ïã†Î¢∞ÎèÑ ÏûÑÍ≥ÑÍ∞í\n",
    "            save_dir='test_results'  # ÏòàÏ∏° Í≤∞Í≥º Ï†ÄÏû• Í≤ΩÎ°ú\n",
    "        )\n",
    "        print(f\"{img_name} ÏòàÏ∏° ÏôÑÎ£å ‚Üí test_results ÎîîÎ†âÌÜ†Î¶¨ ÌôïÏù∏\")\n",
    "\n",
    "visualize_extreme_diverse_predictions(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4672edde",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "import cv2 as cv\n",
    "from collections import Counter\n",
    "\n",
    "model = YOLO(\"runs/detect/train54/weights/best.pt\")\n",
    "\n",
    "# ÌÅ¥ÎûòÏä§Î≥Ñ threshold ÏÑ§Ï†ï (ÏòàÏãú: ÌÅ¥ÎûòÏä§ Ïù¥Î¶Ñ Í∏∞Ï§Ä)\n",
    "class_thresholds = {\n",
    "    'sinkhole': 0.01,    # sinkholeÏùÄ ÎÇÆÏùÄ thresholdÎ°ú Îçî ÎßéÏù¥ ÌÉêÏßÄ\n",
    "    'fire': 0.3,         # fireÏùÄ ÎÜíÏùÄ thresholdÎ°ú Ï†ïÌôïÎèÑ Ïö∞ÏÑ†\n",
    "    'accident': 0.7,\n",
    "    'flood': 0.5\n",
    "}\n",
    "\n",
    "# ÌÅ¥ÎûòÏä§ Ïù¥Î¶ÑÏùÑ IDÎ°ú Î≥ÄÌôò (data.yamlÏùò names ÏàúÏÑúÏôÄ ÏùºÏπòÌï¥Ïïº Ìï®)\n",
    "class_names = model.names\n",
    "class_id_to_threshold = {\n",
    "    class_id: class_thresholds[class_name] \n",
    "    for class_id, class_name in class_names.items() \n",
    "    if class_name in class_thresholds\n",
    "}\n",
    "\n",
    "sink_video_path = \"C:\\\\Users\\\\user\\\\Downloads\\\\Man on a scooter plunges into sinkhole.mp4\"\n",
    "acci_video_path = \"C:\\\\Users\\\\user\\\\Downloads\\\\Shocking rear-end crash in Wordsley caught on CCTV.mp4\"\n",
    "fire_video_path = \"C:\\\\Users\\\\user\\\\Downloads\\\\RAW Traffic camera shows vehicle fire on I-94E near Clearwater.mp4\"\n",
    "flood_video_path = \"C:\\\\Users\\\\user\\\\Downloads\\\\Security camera footage captures deadly flood in Quito   AFP.mp4\"\n",
    "normal_video_path = \"C:\\\\Users\\\\user\\\\Downloads\\\\ordinary.mp4\"\n",
    "ezfire_video_path = \"C:\\\\Users\\\\user\\\\Downloads\\\\easy_fire.mp4\"\n",
    "\n",
    "cap = cv.VideoCapture(normal_video_path)\n",
    "\n",
    "fps = cap.get(cv.CAP_PROP_FPS) or 30\n",
    "\n",
    "frame_buffer = []\n",
    "threshold_frames = 10\n",
    "consecutive_detection_required = 5\n",
    "detection_count = 0\n",
    "detected_classes = []\n",
    "event_start_frame = None\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "    frame_buffer.append(frame)\n",
    "\n",
    "    if len(frame_buffer) == 15:\n",
    "        current_frame = int(cap.get(cv.CAP_PROP_POS_FRAMES))\n",
    "        batch_start_frame = current_frame - 15\n",
    "\n",
    "        # 1. ÎÇÆÏùÄ ÏûÑÍ≥ÑÍ∞íÏúºÎ°ú Î™®Îì† ÌõÑÎ≥¥ ÌÉêÏßÄ (ÌÅ¥ÎûòÏä§Î≥Ñ ÌïÑÌÑ∞ÎßÅÏùÑ ÏúÑÌï¥)\n",
    "        results = model.predict(frame_buffer, imgsz=800, device='cuda', batch=15, conf=0.01)\n",
    "\n",
    "        detected_frames = 0\n",
    "        current_batch_classes = []\n",
    "        \n",
    "        # 2. ÌÅ¥ÎûòÏä§Î≥Ñ threshold Ï†ÅÏö©ÌïòÏó¨ ÌïÑÌÑ∞ÎßÅ\n",
    "        for result in results:\n",
    "            valid_detections = []\n",
    "            if len(result.boxes) > 0:\n",
    "                for box in result.boxes:\n",
    "                    cls = int(box.cls.item())\n",
    "                    conf = box.conf.item()\n",
    "                    # Ìï¥Îãπ ÌÅ¥ÎûòÏä§Ïùò threshold ÌôïÏù∏\n",
    "                    if cls in class_id_to_threshold and conf >= class_id_to_threshold[cls]:\n",
    "                        valid_detections.append(cls)\n",
    "            \n",
    "            # Ïú†Ìö®Ìïú detectionÏù¥ ÏûàÎäî Í≤ΩÏö∞Îßå Ïπ¥Ïö¥Ìä∏\n",
    "            if len(valid_detections) > 0:\n",
    "                detected_frames += 1\n",
    "                current_batch_classes.extend(valid_detections)\n",
    "\n",
    "        # ÎÇòÎ®∏ÏßÄ Î°úÏßÅÏùÄ ÎèôÏùº\n",
    "        if detected_frames >= threshold_frames:\n",
    "            detection_count += 1\n",
    "            detected_classes.extend(current_batch_classes)\n",
    "            \n",
    "            if detection_count == 1:\n",
    "                event_start_frame = batch_start_frame\n",
    "                \n",
    "            print(f\"Detection {detection_count} times in a row\")\n",
    "        else:\n",
    "            detection_count = 0\n",
    "            detected_classes = []\n",
    "            event_start_frame = None\n",
    "\n",
    "        if detection_count >= consecutive_detection_required:\n",
    "            event_end_frame = current_frame - 1\n",
    "            start_time_sec = event_start_frame / fps\n",
    "            end_time_sec = event_end_frame / fps\n",
    "            \n",
    "            start_min = int(start_time_sec // 60)\n",
    "            start_sec = int(start_time_sec % 60)\n",
    "            end_min = int(end_time_sec // 60)\n",
    "            end_sec = int(end_time_sec % 60)\n",
    "            \n",
    "            class_counts = Counter(detected_classes)\n",
    "            \n",
    "            print(\"\\nüö® Event detected!\")\n",
    "            print(f\"‚è∞ Time: {start_min}:{start_sec:02d} ~ {end_min}:{end_sec:02d}\")\n",
    "            print(\"üì¶ Detected classes (with class-specific thresholds):\")\n",
    "            for cls, count in class_counts.items():\n",
    "                print(f\"- {model.names[cls]} (threshold: {class_id_to_threshold[cls]}): {count} times\")\n",
    "            \n",
    "            detection_count = 0\n",
    "            detected_classes = []\n",
    "            event_start_frame = None\n",
    "\n",
    "        frame_buffer = []\n",
    "\n",
    "cap.release()\n",
    "print(\"Processing finished.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c309f5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"C:\\Users\\user\\Desktop\\asdasdqw.png\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
