{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "41a825b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "import os\n",
    "import shutil\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "import ultralytics\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import defaultdict\n",
    "from pathlib import Path\n",
    "import glob\n",
    "import optuna\n",
    "from optuna.visualization import (\n",
    "    plot_optimization_history,\n",
    "    plot_param_importances,\n",
    "    plot_parallel_coordinate,\n",
    "    plot_slice\n",
    ")\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import random\n",
    "from PIL import Image, ImageEnhance, ImageOps\n",
    "os.environ['CUBLAS_WORKSPACE_CONFIG'] = ':4096:8'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "49cd636d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch 버전: 2.0.1+cu117\n",
      "CUDA 사용 가능: True\n",
      "Ultralytics 버전: 8.3.0\n",
      "CUDA 버전: 11.7\n",
      "모델 작업 유형: detect\n"
     ]
    }
   ],
   "source": [
    "print(f\"PyTorch 버전: {torch.__version__}\")\n",
    "print(f\"CUDA 사용 가능: {torch.cuda.is_available()}\")\n",
    "print(f\"Ultralytics 버전: {ultralytics.__version__}\")\n",
    "print(f\"CUDA 버전: {torch.version.cuda}\")\n",
    "\n",
    "model = YOLO('yolov8n.pt')\n",
    "print(f\"모델 작업 유형: {model.task}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "da6530c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 자동 정제 스크립트 (박스 우선 유지)\n",
    "\n",
    "def clean_labels(label_dir):\n",
    "    for filename in os.listdir(label_dir):\n",
    "        filepath = os.path.join(label_dir, filename)\n",
    "        with open(filepath, 'r') as f:\n",
    "            lines = [l for l in f.readlines() if len(l.split()) == 5]\n",
    "        \n",
    "        with open(filepath, 'w') as f:\n",
    "            f.writelines(lines)\n",
    "        \n",
    "clean_labels(\"C:/Users/user/Downloads/dataset/datasetHard/labels/train\")\n",
    "clean_labels(\"C:/Users/user/Downloads/dataset/datasetHard/labels/val\")\n",
    "clean_labels(\"C:/Users/user/Downloads/dataset/datasetHard/labels/test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "aaaef3d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "삭제된 비어있는 라벨 파일: 0개\n",
      "함께 삭제된 이미지 파일: 0개\n",
      "삭제된 비어있는 라벨 파일: 0개\n",
      "함께 삭제된 이미지 파일: 0개\n",
      "삭제된 비어있는 라벨 파일: 0개\n",
      "함께 삭제된 이미지 파일: 0개\n"
     ]
    }
   ],
   "source": [
    "# 비어있는 파일이 있는 경우 성능 저하를 야기할 수 있으므로 비어 있는 label 파일과 이미지도 같이 삭제하는 파일\n",
    "\n",
    "def clean_empty_labels(label_dir, image_dir=None, delete_images=False):\n",
    "    label_dir = Path(label_dir)\n",
    "    if image_dir:\n",
    "        image_dir = Path(image_dir)\n",
    "\n",
    "    removed_labels = 0\n",
    "    removed_images = 0\n",
    "\n",
    "    for label_file in label_dir.glob(\"*.txt\"):\n",
    "        if label_file.stat().st_size == 0:  # 파일이 비어있는지 확인\n",
    "            # 라벨 파일 삭제\n",
    "            label_file.unlink()\n",
    "            removed_labels += 1\n",
    "\n",
    "            if delete_images and image_dir:\n",
    "                # 이미지 파일명 추정 (확장자 jpg, png 등)\n",
    "                stem = label_file.stem\n",
    "                for ext in ['.jpg', '.jpeg', '.png', '.bmp']:\n",
    "                    img_file = image_dir / f\"{stem}{ext}\"\n",
    "                    if img_file.exists():\n",
    "                        img_file.unlink()\n",
    "                        removed_images += 1\n",
    "                        break\n",
    "\n",
    "    print(f\"삭제된 비어있는 라벨 파일: {removed_labels}개\")\n",
    "    if delete_images:\n",
    "        print(f\"함께 삭제된 이미지 파일: {removed_images}개\")\n",
    "\n",
    "        \n",
    "# 라벨과 이미지 모두 삭제\n",
    "clean_empty_labels(\n",
    "    label_dir=r\"C:\\Users\\user\\Downloads\\dataset\\datasetHard\\labels\\train\",\n",
    "    image_dir=r\"C:\\Users\\user\\Downloads\\dataset\\datasetHard\\images\\train\",\n",
    "    delete_images=True\n",
    ")\n",
    "\n",
    "clean_empty_labels(\n",
    "    label_dir=r\"C:\\Users\\user\\Downloads\\dataset\\datasetHard\\labels\\val\",\n",
    "    image_dir=r\"C:\\Users\\user\\Downloads\\dataset\\datasetHard\\images\\val\",\n",
    "    delete_images=True\n",
    ")\n",
    "\n",
    "clean_empty_labels(\n",
    "    label_dir=r\"C:\\Users\\user\\Downloads\\dataset\\datasetHard\\labels\\test\",\n",
    "    image_dir=r\"C:\\Users\\user\\Downloads\\dataset\\datasetHard\\images\\test\",\n",
    "    delete_images=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7cbf1e65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[C:\\Users\\user\\Downloads\\dataset\\datasetHard\\labels\\train] 비어있는 파일이 존재하지 않습니다.\n",
      "[C:\\Users\\user\\Downloads\\dataset\\datasetHard\\labels\\val] 비어있는 파일이 존재하지 않습니다.\n",
      "[C:\\Users\\user\\Downloads\\dataset\\datasetHard\\labels\\test] 비어있는 파일이 존재하지 않습니다.\n"
     ]
    }
   ],
   "source": [
    "# 비어있는 파일이 존재하는지 확인하는 코드\n",
    "\n",
    "def check_labels(label_path):\n",
    "    empty_found = False  # 비어있는 파일이 발견되었는지 여부\n",
    "    for lbl_file in Path(label_path).glob(\"*.txt\"):\n",
    "        with open(lbl_file) as f:\n",
    "            lines = f.readlines()\n",
    "            if not lines:\n",
    "                print(f\"Empty file: {lbl_file}\")\n",
    "                empty_found = True\n",
    "            for line in lines:\n",
    "                parts = line.strip().split()\n",
    "                if len(parts) != 5:\n",
    "                    print(f\"Invalid line in {lbl_file}: {line}\")\n",
    "    if not empty_found:\n",
    "        print(f\"[{label_path}] 비어있는 파일이 존재하지 않습니다.\")\n",
    "\n",
    "check_labels(r\"C:\\Users\\user\\Downloads\\dataset\\datasetHard\\labels\\train\")\n",
    "check_labels(r\"C:\\Users\\user\\Downloads\\dataset\\datasetHard\\labels\\val\")\n",
    "check_labels(r\"C:\\Users\\user\\Downloads\\dataset\\datasetHard\\labels\\test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4e44460a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0개의 캐시 파일 삭제 완료\n"
     ]
    }
   ],
   "source": [
    "# YOLO 학습 과정에서 생성되는 캐시 파일 삭제하는 코드\n",
    "\n",
    "cache_files = glob.glob(r\"C:/Users/user/Downloads/dataset/datasetHard/labels/*.cache\")\n",
    "for f in cache_files:\n",
    "    os.remove(f)\n",
    "print(f\"{len(cache_files)}개의 캐시 파일 삭제 완료\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6067b7b8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train 클래스별 인스턴스 수:\n",
      "Class 0: 4256개\n",
      "Class 1: 2596개\n",
      "Class 2: 5858개\n",
      "Class 3: 786개\n",
      "val 클래스별 인스턴스 수:\n",
      "Class 0: 408개\n",
      "Class 1: 137개\n",
      "Class 2: 251개\n",
      "Class 3: 140개\n",
      "test 클래스별 인스턴스 수:\n",
      "Class 0: 192개\n",
      "Class 1: 284개\n",
      "Class 2: 135개\n",
      "Class 3: 176개\n"
     ]
    }
   ],
   "source": [
    "# 클래스별 인스턴스 수를 확인할 수 있는 코드\n",
    "\n",
    "def count_instance_per_class(name, label_dir):\n",
    "    class_counts = defaultdict(int)\n",
    "\n",
    "    for label_file in Path(label_dir).glob(\"*.txt\"):\n",
    "        with open(label_file) as f:\n",
    "            for line in f:\n",
    "                if line.strip():\n",
    "                    class_id = int(line.split()[0])\n",
    "                    class_counts[class_id] += 1\n",
    "\n",
    "    print(\"{} 클래스별 인스턴스 수:\".format(name))\n",
    "    class_counts = dict(sorted(class_counts.items()))\n",
    "    for cls, cnt in class_counts.items():\n",
    "        print(f\"Class {cls}: {cnt}개\")\n",
    "\n",
    "count_instance_per_class(\"train\", r\"C:\\Users\\user\\Downloads\\dataset\\datasetHard\\labels\\train\")\n",
    "count_instance_per_class(\"val\", r\"C:\\Users\\user\\Downloads\\dataset\\datasetHard\\labels\\val\")\n",
    "count_instance_per_class(\"test\", r\"C:\\Users\\user\\Downloads\\dataset\\datasetHard\\labels\\test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfc1d791",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 하이퍼파리미터 + 파라미터 튜닝 하는 부분\n",
    "\n",
    "def objective(trial):\n",
    "    try:\n",
    "        # 하이퍼파라미터 서제스쳔\n",
    "        lr0 = trial.suggest_float('lr0', 1e-4, 1e-1, log=True)\n",
    "        batch = trial.suggest_categorical('batch', [8, 16, 32])\n",
    "        mosaic = trial.suggest_float('mosaic', 0.0, 1.0)\n",
    "        epochs = 50  # 고정값 사용\n",
    "\n",
    "        # 모델 초기화 및 학습\n",
    "        model = YOLO('yolov8n.pt')\n",
    "        results = model.train(\n",
    "            data=r\"C:\\Users\\user\\Downloads\\dataset\\datasetHard\\data.yaml\",\n",
    "            epochs=epochs,\n",
    "            lr0=lr0,\n",
    "            batch=batch,\n",
    "            mosaic=mosaic,\n",
    "            imgsz=800,\n",
    "            device='cuda',\n",
    "            patience=20,\n",
    "            verbose=False,  # 학습 로그 간소화\n",
    "            amp=True,       # 메모리 절약\n",
    "            plots=False     # Optuna 실행시 플롯 생성 방지\n",
    "        )\n",
    "\n",
    "        # mAP50 값 추출 (Ultralytics 버전별 호환성 처리)\n",
    "        try:\n",
    "            map50 = results.metrics['metrics/val_map_0.5']\n",
    "        except AttributeError:\n",
    "            map50 = results.metrics.map_50  # 8.3.0+ 버전\n",
    "\n",
    "        return map50\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Trial failed with error: {e}\")\n",
    "        return 0.0  # 실패시 0 반환\n",
    "\n",
    "# Optuna 스터디 실행\n",
    "study = optuna.create_study(\n",
    "    direction='maximize',\n",
    "    sampler=optuna.samplers.TPESampler(seed=42)  # 재현성 위해 시드 고정\n",
    ")\n",
    "study.optimize(objective, n_trials=10, show_progress_bar=True)\n",
    "\n",
    "# 결과 출력\n",
    "print(\"\\n=== Best parameters ===\")\n",
    "print(study.best_params)\n",
    "print(f\"Best mAP50: {study.best_value:.3f}\")\n",
    "\n",
    "# 시각화\n",
    "plot_optimization_history(study).show()\n",
    "plot_param_importances(study).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0b688b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 최적화 하이퍼파라미터와 파러미터 간 상관관계, 파라미터별 성능 분포 시각화 파트\n",
    "\n",
    "# 1. 최적화 히스토리(각 trial별 best value 변화)\n",
    "fig1 = plot_optimization_history(study)\n",
    "fig1.show()\n",
    "\n",
    "# 2. 하이퍼파라미터 중요도(어떤 파라미터가 성능에 영향이 큰지)\n",
    "fig2 = plot_param_importances(study)\n",
    "fig2.show()\n",
    "\n",
    "# 3. 파라미터 간 상관관계(Parallel Coordinate)\n",
    "fig3 = plot_parallel_coordinate(study)\n",
    "fig3.show()\n",
    "\n",
    "# 4. 파라미터별 성능 분포(Slice Plot)\n",
    "fig4 = plot_slice(study)\n",
    "fig4.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1579d60f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model path: runs/detect/train54/weights/best.pt\n",
      "\n",
      "📊 Threshold별 테스트 결과\n",
      "Threshold |   mAP50   | Precision |  Recall\n",
      "---------------------------------------------\n",
      "Ultralytics 8.3.0  Python-3.10.9 torch-2.0.1+cu117 CUDA:0 (NVIDIA GeForce RTX 3080, 10240MiB)\n",
      "Model summary (fused): 186 layers, 2,685,148 parameters, 0 gradients, 6.8 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\Users\\user\\Downloads\\dataset\\dataset\\labels\\test.cache... 561 images, 0 backgrounds, 0 corrupt: 100%|█\u001b[0m\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 18/18 [00:45\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        561        687      0.883      0.827      0.884      0.668\n",
      "                 flood        135        207       0.86      0.816       0.85      0.712\n",
      "                  fire        106        142      0.924      0.965      0.976      0.697\n",
      "              accident        236        249      0.902      0.775      0.885      0.626\n",
      "              sinkhole         84         89      0.844      0.753      0.824      0.635\n",
      "Speed: 0.8ms preprocess, 2.4ms inference, 0.0ms loss, 1.0ms postprocess per image\n",
      "Results saved to \u001b[1mruns\\detect\\disaster_detection_test31\u001b[0m\n",
      "  0.8835  |  0.8825  |  0.8272\n"
     ]
    }
   ],
   "source": [
    "# threshold를 변경해가면서 test\n",
    "\n",
    "def test_model_with_thresholds(model,test_params):\n",
    "    results_list = []\n",
    "    print(\"\\n📊 Threshold별 테스트 결과\")\n",
    "    print(\"Threshold |   mAP50   | Precision |  Recall\")\n",
    "    print(\"---------------------------------------------\")\n",
    "\n",
    "    test_params['conf'] = 0.01\n",
    "    results = model.val(**test_params)\n",
    "        # 결과 저장 및 출력\n",
    "    map50 = results.box.map50\n",
    "    precision = np.mean(results.box.p)\n",
    "    recall = np.mean(results.box.r)\n",
    "    print(f\"  {map50:.4f}  |  {precision:.4f}  |  {recall:.4f}\")\n",
    "    results_list.append({\n",
    "        'threshold': 0.01,\n",
    "        'mAP50': map50,\n",
    "        'precision': precision,\n",
    "        'recall': recall\n",
    "    })\n",
    "    return results_list\n",
    "\n",
    "# 1. 모델 로드\n",
    "best_model_path = \"runs/detect/train54/weights/best.pt\"\n",
    "print(\"Best model path:\", best_model_path)\n",
    "model = YOLO(best_model_path)\n",
    "\n",
    "# 2. 테스트 파라미터 설정\n",
    "test_params = {\n",
    "    'data': r\"C:\\Users\\user\\Downloads\\dataset\\datasetHard\\data.yaml\",\n",
    "    'split': 'test',\n",
    "    'batch': 32,\n",
    "    'name': 'disaster_detection_test',\n",
    "    'plots': True,\n",
    "    'save_json': False\n",
    "}\n",
    " \n",
    "results = test_model_with_thresholds(model, test_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfa3a421",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 랜덤 5개 이미지에 대한 테스트 시각화\n",
    "\n",
    "def visualize_extreme_diverse_predictions(model):\n",
    "    test_images_dir = r\"C:\\Users\\user\\Downloads\\dataset\\datasetHard\\images\\test\"\n",
    "    all_images = os.listdir(test_images_dir)\n",
    "\n",
    "    # 파일명에서 첫 단어로 그룹화\n",
    "    image_groups = defaultdict(list)\n",
    "    for img in all_images:\n",
    "        if img:\n",
    "            group_key = img.split('_')[0]  # 예: 'cat_01.jpg' → 'cat'\n",
    "            image_groups[group_key].append(img)\n",
    "\n",
    "    # 각 그룹에서 하나씩 뽑아 다양성 확보\n",
    "    selected_images = [random.choice(group) for group in image_groups.values()]\n",
    "\n",
    "    # 그룹이 5개 이상이면 랜덤하게 5개만 선택\n",
    "    if len(selected_images) > 5:\n",
    "        selected_images = random.sample(selected_images, 5)\n",
    "\n",
    "    # 선택된 이미지에 대해 예측 및 결과 저장\n",
    "    for img_name in selected_images:\n",
    "        img_path = os.path.join(test_images_dir, img_name)\n",
    "        results = model.predict(\n",
    "            source=img_path,\n",
    "            save=True,\n",
    "            conf=0.01,  # 신뢰도 임계값\n",
    "            save_dir='test_results'  # 예측 결과 저장 경로\n",
    "        )\n",
    "        print(f\"{img_name} 예측 완료 → test_results 디렉토리 확인\")\n",
    "\n",
    "visualize_extreme_diverse_predictions(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4672edde",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "import cv2 as cv\n",
    "from collections import Counter\n",
    "\n",
    "model = YOLO(\"runs/detect/train54/weights/best.pt\")\n",
    "\n",
    "# 클래스별 threshold 설정 (예시: 클래스 이름 기준)\n",
    "class_thresholds = {\n",
    "    'sinkhole': 0.01,    # sinkhole은 낮은 threshold로 더 많이 탐지\n",
    "    'fire': 0.3,         # fire은 높은 threshold로 정확도 우선\n",
    "    'accident': 0.7,\n",
    "    'flood': 0.5\n",
    "}\n",
    "\n",
    "# 클래스 이름을 ID로 변환 (data.yaml의 names 순서와 일치해야 함)\n",
    "class_names = model.names\n",
    "class_id_to_threshold = {\n",
    "    class_id: class_thresholds[class_name] \n",
    "    for class_id, class_name in class_names.items() \n",
    "    if class_name in class_thresholds\n",
    "}\n",
    "\n",
    "sink_video_path = \"C:\\\\Users\\\\user\\\\Downloads\\\\Man on a scooter plunges into sinkhole.mp4\"\n",
    "acci_video_path = \"C:\\\\Users\\\\user\\\\Downloads\\\\Shocking rear-end crash in Wordsley caught on CCTV.mp4\"\n",
    "fire_video_path = \"C:\\\\Users\\\\user\\\\Downloads\\\\RAW Traffic camera shows vehicle fire on I-94E near Clearwater.mp4\"\n",
    "flood_video_path = \"C:\\\\Users\\\\user\\\\Downloads\\\\Security camera footage captures deadly flood in Quito   AFP.mp4\"\n",
    "normal_video_path = \"C:\\\\Users\\\\user\\\\Downloads\\\\ordinary.mp4\"\n",
    "ezfire_video_path = \"C:\\\\Users\\\\user\\\\Downloads\\\\easy_fire.mp4\"\n",
    "\n",
    "cap = cv.VideoCapture(normal_video_path)\n",
    "\n",
    "fps = cap.get(cv.CAP_PROP_FPS) or 30\n",
    "\n",
    "frame_buffer = []\n",
    "threshold_frames = 10\n",
    "consecutive_detection_required = 5\n",
    "detection_count = 0\n",
    "detected_classes = []\n",
    "event_start_frame = None\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "    frame_buffer.append(frame)\n",
    "\n",
    "    if len(frame_buffer) == 15:\n",
    "        current_frame = int(cap.get(cv.CAP_PROP_POS_FRAMES))\n",
    "        batch_start_frame = current_frame - 15\n",
    "\n",
    "        # 1. 낮은 임계값으로 모든 후보 탐지 (클래스별 필터링을 위해)\n",
    "        results = model.predict(frame_buffer, imgsz=800, device='cuda', batch=15, conf=0.01)\n",
    "\n",
    "        detected_frames = 0\n",
    "        current_batch_classes = []\n",
    "        \n",
    "        # 2. 클래스별 threshold 적용하여 필터링\n",
    "        for result in results:\n",
    "            valid_detections = []\n",
    "            if len(result.boxes) > 0:\n",
    "                for box in result.boxes:\n",
    "                    cls = int(box.cls.item())\n",
    "                    conf = box.conf.item()\n",
    "                    # 해당 클래스의 threshold 확인\n",
    "                    if cls in class_id_to_threshold and conf >= class_id_to_threshold[cls]:\n",
    "                        valid_detections.append(cls)\n",
    "            \n",
    "            # 유효한 detection이 있는 경우만 카운트\n",
    "            if len(valid_detections) > 0:\n",
    "                detected_frames += 1\n",
    "                current_batch_classes.extend(valid_detections)\n",
    "\n",
    "        # 나머지 로직은 동일\n",
    "        if detected_frames >= threshold_frames:\n",
    "            detection_count += 1\n",
    "            detected_classes.extend(current_batch_classes)\n",
    "            \n",
    "            if detection_count == 1:\n",
    "                event_start_frame = batch_start_frame\n",
    "                \n",
    "            print(f\"Detection {detection_count} times in a row\")\n",
    "        else:\n",
    "            detection_count = 0\n",
    "            detected_classes = []\n",
    "            event_start_frame = None\n",
    "\n",
    "        if detection_count >= consecutive_detection_required:\n",
    "            event_end_frame = current_frame - 1\n",
    "            start_time_sec = event_start_frame / fps\n",
    "            end_time_sec = event_end_frame / fps\n",
    "            \n",
    "            start_min = int(start_time_sec // 60)\n",
    "            start_sec = int(start_time_sec % 60)\n",
    "            end_min = int(end_time_sec // 60)\n",
    "            end_sec = int(end_time_sec % 60)\n",
    "            \n",
    "            class_counts = Counter(detected_classes)\n",
    "            \n",
    "            print(\"\\n🚨 Event detected!\")\n",
    "            print(f\"⏰ Time: {start_min}:{start_sec:02d} ~ {end_min}:{end_sec:02d}\")\n",
    "            print(\"📦 Detected classes (with class-specific thresholds):\")\n",
    "            for cls, count in class_counts.items():\n",
    "                print(f\"- {model.names[cls]} (threshold: {class_id_to_threshold[cls]}): {count} times\")\n",
    "            \n",
    "            detection_count = 0\n",
    "            detected_classes = []\n",
    "            event_start_frame = None\n",
    "\n",
    "        frame_buffer = []\n",
    "\n",
    "cap.release()\n",
    "print(\"Processing finished.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c309f5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"C:\\Users\\user\\Desktop\\asdasdqw.png\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
